{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **What is PyTorch?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## **Tensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Tensor（张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3006, 0.1242, 0.1545],\n",
       "        [0.5451, 0.0697, 0.9736],\n",
       "        [0.7739, 0.6581, 0.2114],\n",
       "        [0.5682, 0.0587, 0.7223],\n",
       "        [0.2930, 0.3357, 0.2922]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 3) #创建一个随机初始化矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3]) #直接从数据构造张量\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.9420,  0.0035, -0.6216],\n",
      "        [-1.2788, -0.5294,  0.8495],\n",
      "        [ 1.6196, -0.5824, -0.2372],\n",
      "        [ 1.8058,  1.8491,  0.2183],\n",
      "        [ 0.3486,  0.1658,  1.7811]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double) #根据已有的tensor建立新的tensor。\n",
    "                                         #除非用户提供新的值，否则这些方法将重用输入张量的属性，例如dtype等\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size()) #获取它的形状\n",
    "                #torch.Size实际上是一个tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**运算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1594, 0.8395, 0.2657],\n",
      "        [0.5238, 0.0794, 0.8617],\n",
      "        [0.9091, 0.1758, 0.3135],\n",
      "        [0.3704, 0.9744, 0.5074],\n",
      "        [0.9853, 0.3415, 0.7607]])\n",
      "tensor([[-0.7825,  0.8430, -0.3559],\n",
      "        [-0.7550, -0.4501,  1.7112],\n",
      "        [ 2.5287, -0.4066,  0.0762],\n",
      "        [ 2.1761,  2.8235,  0.7256],\n",
      "        [ 1.3339,  0.5073,  2.5418]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3) \n",
    "print(y)\n",
    "print(x + y) #相同形状 逐个运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7825,  0.8430, -0.3559],\n",
      "        [-0.7550, -0.4501,  1.7112],\n",
      "        [ 2.5287, -0.4066,  0.0762],\n",
      "        [ 2.1761,  2.8235,  0.7256],\n",
      "        [ 1.3339,  0.5073,  2.5418]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y)) #另一种形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7825,  0.8430, -0.3559],\n",
      "        [-0.7550, -0.4501,  1.7112],\n",
      "        [ 2.5287, -0.4066,  0.0762],\n",
      "        [ 2.1761,  2.8235,  0.7256],\n",
      "        [ 1.3339,  0.5073,  2.5418]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3) #给定一个输出张量作为参数\n",
    "torch.add(x, y, out=result) \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7825,  0.8430, -0.3559],\n",
      "        [-0.7550, -0.4501,  1.7112],\n",
      "        [ 2.5287, -0.4066,  0.0762],\n",
      "        [ 2.1761,  2.8235,  0.7256],\n",
      "        [ 1.3339,  0.5073,  2.5418]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x) #原位/原地操作（in-place）\n",
    "print(y)\n",
    "\n",
    "#任何一个in-place改变张量的操作后面都固定一个_。例如x.copy_(y)、x.t_()将更改x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9420,  0.0035, -0.6216],\n",
      "        [-1.2788, -0.5294,  0.8495],\n",
      "        [ 1.6196, -0.5824, -0.2372],\n",
      "        [ 1.8058,  1.8491,  0.2183],\n",
      "        [ 0.3486,  0.1658,  1.7811]])\n",
      "tensor([-1.2788, -0.5294,  0.8495])\n",
      "tensor([ 0.0035, -0.5294, -0.5824,  1.8491,  0.1658])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x[1, :]) #输出第二行\n",
    "print(x[:, 1]) #输出第二列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**如果想改变形状，可以使用torch.view**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**如果是仅包含一个元素的tensor，可以使用.item()来得到对应的python数值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1431])\n",
      "0.14310623705387115\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**More:https://pytorch.org/docs/stable/torch.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## **NumPy Bridge**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**将一个Torch张量转换为一个NumPy数组是轻而易举的事情，反之亦然。Torch张量和NumPy数组将共享它们的底层内存位置，更改一个将更改另一个。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**将torch的Tensor转化为NumPy数组**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**将NumPy数组转化为Torch张量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## **CUDA上的张量**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**张量可以使用.to方法移动到任何设备（device）上：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# 我们将使用`torch.device`来将tensor移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建tensor\n",
    "    x = x.to(device)                       # 或者使用`.to(\"cuda\")`方法\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to`也能在移动时改变dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# **Autograd：自动求导**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**PyTorch中，所有神经网络的核心是autograd包，torch.Tensor是这个包的核心类。如果设置它的属性 .requires_grad为True，那么它将会追踪对于该张量的所有操作。当完成计算后可以通过调用.backward()，来自动计算所有的梯度。这个张量的所有梯度将会自动累加到.grad属性.**\n",
    "\n",
    "**要阻止一个张量被跟踪历史，可以调用.detach()方法将其与计算历史分离，并阻止它未来的计算记录被跟踪。**\n",
    "\n",
    "**为了防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad():中。在评估模型时特别有用，因为模型可能具有requires_grad = True的可训练的参数，但是我们不需要在此过程中对他们进行梯度计算。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Tensor和Function互相连接生成了一个非循环图，它编码了完整的计算历史。每个张量都有一个.grad_fn属性，它引用了一个创建了这个Tensor的Function**\n",
    "\n",
    "**如果需要计算导数，可以在Tensor上调用.backward()。如果Tensor是一个标量（即它包含一个元素的数据），则不需要为backward()指定任何参数，但是如果它有更多的元素，则需要指定一个gradient参数，它是形状匹配的张量。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## **requires_grad以及grad_fn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y *3\n",
    "out = z.mean() #求平均值\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**mean() 求均值,另外的用法：torch.mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27., 27.], grad_fn=<MeanBackward2>)\n"
     ]
    }
   ],
   "source": [
    "aa = torch.mean(z, 1)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**.requires_grad_(...) 原地改变了现有张量的 requires_grad 标志。如果没有指定的话，默认输入的这个标志是False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True <SumBackward0 object at 0x00000238F4723208>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.requires_grad, b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## **梯度**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**因为out是一个标量。所以让我们直接进行反向传播，out.backward()和out.backward(torch.tensor(1.))等价**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad) #输出导数d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0106, -0.7078,  0.0667], requires_grad=True)\n",
      "tensor([  -21.7552, -1449.5798,   136.4996], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**torch.no_grad()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# **神经网络**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**可以使用torch.nn包来构建神经网络.**\n",
    "\n",
    "**nn包依赖于autograd包来定义模型并对它们求导。**\n",
    "\n",
    "**一个nn.Module包含各个层和一个forward(input)方法，该方法返回output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*神经网络训练过程*\n",
    "\n",
    "**1.定义网络（传入参数或者权重）**\n",
    "\n",
    "**2.遍历输入数据集**\n",
    "\n",
    "**3.通过网络处理输入**\n",
    "\n",
    "**4.计算损失函数**\n",
    "\n",
    "**5.把梯度传回网络的参数**\n",
    "\n",
    "**6.更新网络的权重,常用：weight = weight - learning_rate * gradient**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **定义网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # 除去批大小维度的其余维度\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**我们只需要定义 forward 函数，可以在 forward 函数中使用任何针对张量的操作和计算。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**一个模型的可学习参数可以通过net.parameters()返回**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0637, -0.0689, -0.2260,  0.0480,  0.0734, -0.0249, -0.0182, -0.1073,\n",
      "         -0.0831,  0.0262]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**清零所有参数的梯度缓存，然后进行随机梯度的反向传播：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## **损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6872, grad_fn=<MseLossBackward>)\n",
      "<MseLossBackward object at 0x00000238F4710B70>\n",
      "<AddmmBackward object at 0x00000238F4733550>\n",
      "<AccumulateGrad object at 0x00000238F4710B70>\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10) \n",
    "target = target.view(1, -1) #变形 使其与output的形状一致\n",
    "criterion = nn.MSELoss() #nn包中的一种，计算输出和目标的均方误差（mean-squared error）。\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## **反向传播**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**调用loss.backward()来反向传播权重。我们需要清零现有的梯度，否则梯度将会与已有的梯度累加。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0023, -0.0205, -0.0020, -0.0029,  0.0095, -0.0072])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad() #清零所有参数的梯度缓存\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## **更新权重**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**SGD是最简单的更新规则，但是我们使用torch.optim这个包来实现各种更新规则**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#创建优化器（optimizer）\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "#在训练的迭代中：\n",
    "optimizer.zero_grad() #清零梯度缓存\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() #更新参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# **训练分类器**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**我们将按顺序做以下步骤：**\n",
    "\n",
    "1.通过torchvision加载CIFAR10里面的训练和测试数据集，并对数据进行标准化\n",
    "\n",
    "2.定义卷积神经网络\n",
    "\n",
    "3.定义损失函数\n",
    "\n",
    "4.利用训练数据训练网络\n",
    "\n",
    "5.利用测试数据测试网络 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **加载并标准化CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**torchvision数据集加载完后的输出是范围在[0, 1]之间的PILImage。我们将其标准化为范围在[-1, 1]之间的张量。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#Composes several transforms together.\n",
    "#ToTensor：Convert a PIL Image or numpy.ndarray to tensor.\n",
    "#Normalize(mean, std, inplace=False)  means标准差，std 方差\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "#参数解释\n",
    "#数据加载程器。组合数据集和采样器，并在数据集上\n",
    "#num_workers 提供单进程(取默认值0时)或多进程迭代器。\n",
    "#shuffle 在每轮epoch打乱数据\n",
    "#num_workers 多少子进程来加载数据，默认0(在主进程)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog',\n",
    "           'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**展示一些训练数据的图片**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plane   car horse   car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#输出图像的函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 随机得到一些训练图片\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 显示图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印图片标签\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **定义卷积神经网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **定义损失函数和优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #momentum 动量梯度下降法的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **训练网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss：2.175\n",
      "[1,  4000] loss：1.889\n",
      "[1,  6000] loss：1.695\n",
      "[1,  8000] loss：1.594\n",
      "[1, 10000] loss：1.547\n",
      "[1, 12000] loss：1.466\n",
      "[2,  2000] loss：1.405\n",
      "[2,  4000] loss：1.383\n",
      "[2,  6000] loss：1.348\n",
      "[2,  8000] loss：1.332\n",
      "[2, 10000] loss：1.299\n",
      "[2, 12000] loss：1.278\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #get the inputs\n",
    "        inputs, labels = data \n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward + backward +optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  #print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss：%.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## **使用测试数据测试网络**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**显示测试集中的图像**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  horse***** ship***** ship*****  car\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 输出图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', '*****'.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**输出是10个类别的量值。一个类的值越高，网络就越认为这个图像属于这个特定的类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted： horse  ship  ship   car\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted：', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**在整个数据集上的表现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images：53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images：%d %%' % \n",
    "      (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**哪些是表现好的类呢？哪些是表现的差的类**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 58 %\n",
      "Accuracy of   car : 79 %\n",
      "Accuracy of  bird : 37 %\n",
      "Accuracy of   cat : 29 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 46 %\n",
      "Accuracy of  frog : 65 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 77 %\n",
      "Accuracy of truck : 29 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1 \n",
    "            \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **在GPU上训练&数据并行处理(略)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
